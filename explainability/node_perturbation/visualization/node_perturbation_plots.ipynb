{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = [\"Africa\", \"North America\", \"South America\", \"Oceania\", \"Eastern Europe\", \"Western Europe\", \"Middle East\", \"South Asia\", \"Southeast-East Asia\", \"Central Asia\"]\n",
    "ANALYSIS_DIR = \"<datetime-stamp of multiple model training run>\"\n",
    "NUM_MODELS = 100\n",
    "MODEL_NAME = \"DCSAGE\"\n",
    "WINDOW_SIZE = 7\n",
    "REC_PRED_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Perturbed Predictions from Models\n",
    "These cells load the roll_win_pert_preds.npy saved array of perturbed recursive predictions, which\n",
    "were saved by the node perturbation analysis file. The array contains recursive predictions under\n",
    "perturbations of each of the 10 nodes. \n",
    "\n",
    "Here we load the saved array, and turn the Numpy array back into a Python list starting from the \n",
    "inside out. We do this since the Pandas DataFrame within the array need to be recovered, and the\n",
    "DataFrames are easily accesible once in Python arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_pert_pred_nested_np = np.load(\"./analysis-runs-multiple-models/{}/prediction_saves/roll_win_pert_preds.npy\".format(ANALYSIS_DIR))\n",
    "roll_win_pert_pred_nested_list = list(roll_win_pert_pred_nested_np)\n",
    "roll_win_pert_pred_nested_list = [list(np_arr) for np_arr in roll_win_pert_pred_nested_list]\n",
    "\n",
    "for rolling_window_idx in range(len(roll_win_pert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_pert_pred_nested_list[0])):\n",
    "        roll_win_pert_pred_nested_list[rolling_window_idx][model_idx] = list(roll_win_pert_pred_nested_list[rolling_window_idx][model_idx])\n",
    "\n",
    "for rolling_window_idx in range(len(roll_win_pert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_pert_pred_nested_list[0])):\n",
    "        for perturbed_idx in range(len(roll_win_pert_pred_nested_list[0][0])):\n",
    "            roll_win_pert_pred_nested_list[rolling_window_idx][model_idx][perturbed_idx] = list(roll_win_pert_pred_nested_list[rolling_window_idx][model_idx][perturbed_idx])\n",
    "\n",
    "for rolling_window_idx in range(len(roll_win_pert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_pert_pred_nested_list[0])):\n",
    "        for perturbed_idx in range(len(roll_win_pert_pred_nested_list[0][0])):\n",
    "            for country_idx in range(len(roll_win_pert_pred_nested_list[0][0][0])):\n",
    "                roll_win_pert_pred_nested_list[rolling_window_idx][model_idx][perturbed_idx][country_idx] = pd.DataFrame(data=roll_win_pert_pred_nested_list[rolling_window_idx][model_idx][perturbed_idx][country_idx], \n",
    "                columns=[\"Regular Predictions\", \"Ground Truth\", \"Extended Recursive Predictions\", \"Day Index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Unperturbed Predictions for Models\n",
    "These cells load the roll_win_unpert_preds.npy array, which contain the unperturbed recursive \n",
    "predictions saved during node perturbation analysis. We again load the array and turn it from \n",
    "a Numpy array back into a Python list of Pandas DataFrames.\n",
    "\n",
    "Since there are 10 country to perturb but only 1 unperturbed dataloader, this array will have\n",
    "1 less dimension that roll_win_pert_preds.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_unpert_pred_nested_np = np.load(\"./analysis-runs-multiple-models/{}/prediction_saves/roll_win_unpert_preds.npy\".format(ANALYSIS_DIR))\n",
    "roll_win_unpert_pred_nested_list = list(roll_win_unpert_pred_nested_np)\n",
    "roll_win_unpert_pred_nested_list = [list(np_arr) for np_arr in roll_win_unpert_pred_nested_list]\n",
    "\n",
    "for rolling_window_idx in range(len(roll_win_unpert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_unpert_pred_nested_list[0])):\n",
    "        roll_win_unpert_pred_nested_list[rolling_window_idx][model_idx] = list(roll_win_unpert_pred_nested_list[rolling_window_idx][model_idx])\n",
    "\n",
    "for rolling_window_idx in range(len(roll_win_unpert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_unpert_pred_nested_list[0])):\n",
    "        for country_idx in range(len(roll_win_unpert_pred_nested_list[0][0])):\n",
    "            roll_win_unpert_pred_nested_list[rolling_window_idx][model_idx][country_idx] = pd.DataFrame(data=roll_win_unpert_pred_nested_list[rolling_window_idx][model_idx][country_idx], \n",
    "            columns=[\"Regular Predictions\", \"Ground Truth\", \"Extended Recursive Predictions\", \"Day Index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Bias Correction\n",
    "\n",
    "Correction factor is average of daywise ratio of ground truth over median curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_correction(window_prediction_np_array, window_idx):\n",
    "    \"\"\"\n",
    "    This function accepts a numpy array of unperturbed predictions on 1 window by all models, and returns \n",
    "    10 numbers representing the bias corrections for 10 continents for the specified window.\n",
    "\n",
    "    Bias correction is computed by putting ground truth on x-axis and mean recursive prediction on y-axis\n",
    "    for each continent, and then calculating slope of the correlation plot.\n",
    "\n",
    "    Args:\n",
    "        - window_prediction_np_array: unperturbed predictions for all models on one window, \n",
    "            shape (100, 10, 30, 4)\n",
    "    \"\"\"\n",
    "    ground_truth = window_prediction_np_array[:,:,:,1]  # shape (100, 10, 30)\n",
    "    ground_truth = ground_truth[0,:,:]  # Ground truth same for all models, get from 1st model. Shape (10, 30)\n",
    "\n",
    "    all_model_recursive_preds = window_prediction_np_array[:,:,:,2]  # shape (100, 10, 30)\n",
    "    median_recursive_pred = np.median(all_model_recursive_preds, axis=0)  # shape (10, 30)\n",
    "\n",
    "    daywise_ratios = ground_truth / median_recursive_pred  # shape (10, 30)\n",
    "    averaged_ratios = np.mean(daywise_ratios, axis=1)  # shape (10,)\n",
    "    return averaged_ratios\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window_bias_corrections = []\n",
    "for window in range(0, len(roll_win_unpert_pred_nested_np)):\n",
    "    window_bias_corrections = bias_correction(roll_win_unpert_pred_nested_np[window], window)\n",
    "    rolling_window_bias_corrections.append(window_bias_corrections)\n",
    "\n",
    "rolling_window_bias_corrections = np.array(rolling_window_bias_corrections)\n",
    "print(rolling_window_bias_corrections.shape)\n",
    "\n",
    "# Take mean of bias correction factors calculated for each node across recursive prediction windows,\n",
    "# obtaining 1 correction factor for each node.\n",
    "window_bias_corrections = np.mean(rolling_window_bias_corrections, axis=0)\n",
    "print(window_bias_corrections.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 100 model Recursive Prediction Visual After Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.node_perturbation_dataloader import Covid10CountriesUnperturbedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_corrected_100_rec_pred_with_starting_input(roll_win_unpert_pred_nested_list, rolling_window):\n",
    "    \"\"\"\n",
    "    This function plots the 5x2 figure where each subplot represents one node. For each subplot, the ground\n",
    "    truth for the node is plotted as a thick orange line, while the 100 other lines colored in black represent\n",
    "    the recursive predictions of the 100 models for that node.\n",
    "\n",
    "    Bias corrections are applied on this plot, according to the average ratio on a window between ground truth and recursive prediction median/mean curve.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_unpert_pred_nested_list: (523, 100, 10, 30, 4)\n",
    "        - rolling window: The window for which to create this plot\n",
    "    \"\"\"\n",
    "    dataset = Covid10CountriesUnperturbedDataset(\n",
    "        dataset_npz_path=\"/Users/syedrizvi/Desktop/Projects/GNN_Project/DCSAGE/Node-Perturbation/datasets/10_continents_dataset_v19_node_pert.npz\",\n",
    "        window_size=WINDOW_SIZE, \n",
    "        data_split=\"entire-dataset-smooth\", \n",
    "        avg_graph_structure=False)\n",
    "    \n",
    "    assert len(dataset.all_window_edge_attr) - WINDOW_SIZE - REC_PRED_LEN == len(roll_win_unpert_pred_nested_list), \"Inconsistent window counts.\"\n",
    "    \n",
    "    first_window_cases = np.zeros((len(roll_win_unpert_pred_nested_list) + WINDOW_SIZE, 10))\n",
    "    first_window_cases[:WINDOW_SIZE,:] = dataset.all_window_node_feat[rolling_window,:,:,1]  # Shape [7, 10]\n",
    "    first_window_cases[first_window_cases == 0] = np.nan\n",
    "\n",
    "    # Make dataset to show first WINDOW_SIZE days that went into model\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(40, 16))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    fig.suptitle(\"DCSAGE Unperturbed Median Ratio Corrected Recursive Predictions Coverage (Window {})\".format(rolling_window), fontsize= 30)\n",
    "\n",
    "    idx = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            visual_dict = {}\n",
    "            for i in range(NUM_MODELS):\n",
    "                vals = np.array(roll_win_unpert_pred_nested_list[rolling_window][i][idx][\"Extended Recursive Predictions\"])  # Shape (30,)\n",
    "                vals *= window_bias_corrections[idx]\n",
    "                vals = np.pad(vals, (WINDOW_SIZE, 0), \"constant\", constant_values=(0,0))\n",
    "                vals[vals == 0] = np.nan\n",
    "                visual_dict[\"Model {}\".format(i)] = vals\n",
    "\n",
    "            visual_dict[\"Day Index\"] = list(range(-1 * WINDOW_SIZE, len(roll_win_unpert_pred_nested_list[rolling_window][0][idx][\"Extended Recursive Predictions\"])))\n",
    "            visual_df = pd.DataFrame(visual_dict)\n",
    "\n",
    "            # Ground truth is same for all models, pick from first model\n",
    "            vals2 = np.array(roll_win_unpert_pred_nested_list[rolling_window][0][idx][\"Ground Truth\"])\n",
    "            vals2 = np.pad(vals2, (WINDOW_SIZE, 0), \"constant\", constant_values=(0,0))\n",
    "            vals2[vals2 == 0] = np.nan\n",
    "            visual_dict2 = {\"Ground Truth\": vals2}\n",
    "            visual_dict2[\"Day Index\"] = list(range(-1 * WINDOW_SIZE, len(roll_win_unpert_pred_nested_list[rolling_window][0][idx][\"Ground Truth\"]))) \n",
    "            visual_df2 = pd.DataFrame(visual_dict2)\n",
    "\n",
    "            visual_df3 = pd.DataFrame({\n",
    "                \"Starting Input\": first_window_cases[:,idx],\n",
    "                \"Day Index\": list(range(-1 * WINDOW_SIZE, len(first_window_cases) - WINDOW_SIZE))\n",
    "            })\n",
    "\n",
    "            sns.lineplot(ax=col, x='Day Index', y='value', hue='variable', data=pd.melt(visual_df, ['Day Index']), palette=['gray'] * NUM_MODELS)\n",
    "            sns.lineplot(ax=col, x='Day Index', y='value', hue='variable', data=pd.melt(visual_df2, ['Day Index']), linewidth = 8, palette=['orange'])\n",
    "            sns.lineplot(ax=col, x='Day Index', y='value', hue='variable', data=pd.melt(visual_df3, ['Day Index']), linewidth = 8, palette=['blue'])\n",
    "            col.set_title(continents[idx])\n",
    "            col.set_ylim([0, 6])\n",
    "            box = col.get_position()\n",
    "            col.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            col.legend().remove()\n",
    "            idx += 1\n",
    "\n",
    "    plt.savefig(\"./window{}_corrected_{}models_rec_pred_coverage.png\".format(rolling_window, NUM_MODELS), bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use same window that bias correction was calculated on\n",
    "for window in range(0, len(roll_win_unpert_pred_nested_list), 50):\n",
    "    plot_bias_corrected_100_rec_pred_with_starting_input(roll_win_unpert_pred_nested_list, rolling_window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply bias correction to all rolling window prediction lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rolling_window_idx in range(len(roll_win_pert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_pert_pred_nested_list[0])):\n",
    "        for perturbed_idx in range(len(roll_win_pert_pred_nested_list[0][0])):\n",
    "            for country_idx in range(len(roll_win_pert_pred_nested_list[0][0][0])):\n",
    "                # (523, 100, 10, 10, 30, 4)\n",
    "                roll_win_pert_pred_nested_list[rolling_window_idx][model_idx][perturbed_idx][country_idx][\"Extended Recursive Predictions\"] *= window_bias_corrections[country_idx]\n",
    "\n",
    "for rolling_window_idx in range(len(roll_win_unpert_pred_nested_list)):\n",
    "    for model_idx in range(len(roll_win_unpert_pred_nested_list[0])):\n",
    "        for country_idx in range(len(roll_win_unpert_pred_nested_list[0][0])):\n",
    "            # (523, 100, 10, 30, 4)\n",
    "            roll_win_unpert_pred_nested_list[rolling_window_idx][model_idx][country_idx][\"Extended Recursive Predictions\"] *= window_bias_corrections[country_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Node Sensitivity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_perturbation_prediction_difference_heatmap(perturb_df_nested_lists, regular_df_nested_list):\n",
    "    \"\"\"\n",
    "    This function is a helper function for computing the difference between perturbed and unperturbed \n",
    "    predictions, a precursor step for computing sensitivity scores later on. This function is meant to \n",
    "    be called for a single model on a single window, and will return prediction difference in the form \n",
    "    of a 10x10 matrix where the row is the perturbed geographical region, and the column represents \n",
    "    the affected region. Each cell represents the difference in perturbed and unperturbed prediction \n",
    "    summed over 30 days of recursive prediction.\n",
    "    \n",
    "    Args:\n",
    "        - perturb_df_nested_lists: (10, 10, 30, 4): 10 perturbed countries, \n",
    "            10 countries in graph, pd.DataFrame of shape (30, 4)\n",
    "        - regular_df_nested_list: (10, 30, 4): 10 countries in graph, pd.DataFrame (30, 4)\n",
    "    \"\"\"\n",
    "    aggreg_differences_lists = []\n",
    "\n",
    "    for perturbed_country_idx in range(10):\n",
    "        aggreg_differences = []\n",
    "        for country_idx in range(10):\n",
    "            if country_idx == perturbed_country_idx:\n",
    "                aggreg_differences.append(np.nan)\n",
    "            else:\n",
    "                difference_list = perturb_df_nested_lists[perturbed_country_idx][country_idx]['Extended Recursive Predictions'] - regular_df_nested_list[country_idx]['Extended Recursive Predictions']\n",
    "                \n",
    "                difference_list = np.abs(difference_list) # Take absolute value of prediction difference\n",
    "                aggreg_differences.append(difference_list.sum())\n",
    "\n",
    "        aggreg_differences_lists.append(aggreg_differences)\n",
    "    return aggreg_differences_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate prediction difference array across entire dataset. If you have previously computed this, skip\n",
    "ahead to load the precomputed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_aggreg_diff_nested_list = []\n",
    "for roll_win_idx in range(len(roll_win_unpert_pred_nested_list)):\n",
    "    if roll_win_idx % 20 == 0:\n",
    "        print(\"Rolling window\", roll_win_idx)\n",
    "\n",
    "    model_sens_score_nested_lists = []\n",
    "    for model_idx in range(len(roll_win_unpert_pred_nested_list[0])):\n",
    "        aggreg_differences_lists = node_perturbation_prediction_difference_heatmap(\n",
    "            roll_win_pert_pred_nested_list[roll_win_idx][model_idx], \n",
    "            roll_win_unpert_pred_nested_list[roll_win_idx][model_idx])\n",
    "        model_sens_score_nested_lists.append(aggreg_differences_lists)\n",
    "    \n",
    "    roll_win_aggreg_diff_nested_list.append(model_sens_score_nested_lists)\n",
    "\n",
    "# roll_win_aggreg_diff_nested_list ends up being [num_windows, num_models, num_nodes, num_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array and save array\n",
    "roll_win_aggreg_diff_nested_list = np.array(roll_win_aggreg_diff_nested_list)\n",
    "print(roll_win_aggreg_diff_nested_list.shape)\n",
    "\n",
    "np.save(\"./{}_7day_100model_meanagg_v19_10x10_bias_corrected_unsigned.npy\".format(MODEL_NAME), np.array(roll_win_aggreg_diff_nested_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously computed and saved the prediction difference array, then run this cell to \n",
    "load in the precomputed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_aggreg_diff_nested_list = np.load(\"./analysis-runs-multiple-models/\" + ANALYSIS_DIR + \"/prediction_saves/DCSAGE_7day_100model_meanagg_v19_10x10_bias_corrected_unsigned.npy\")\n",
    "print(roll_win_aggreg_diff_nested_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Sensitivity Scores From Prediction Difference Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of prediction difference array:\", roll_win_aggreg_diff_nested_list.shape)\n",
    "\n",
    "sensitivty_score_nested_np = np.nansum(np.array(roll_win_aggreg_diff_nested_list), axis=3)\n",
    "print(\"Shape of sensitivity score array:\", sensitivty_score_nested_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Sensitivity Score Trends Over Rolling Windows (All Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_model_sens_score_trends_lineplot(roll_win_aggreg_diff_nested_list):\n",
    "    \"\"\"\n",
    "    This function plots the 5x2 figure of sensitivity score lineplots over rolling windows \n",
    "    (x-axis), where each model is a single line on the subplot (no averaging across models).\n",
    "    Sensitivity scores are calculated by summing across row of 10x10 sensitivity array.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_aggreg_diff_nested_list: 10x10 sensitivity array, shape (num_windows, NUM_MODELS, 10, 10)\n",
    "    \"\"\"\n",
    "    # Sum the fourth dimension to get sensitivity scores, (num_windows, NUM_MODELS, 10).\n",
    "    sensitivty_score_nested_np = np.nansum(np.array(roll_win_aggreg_diff_nested_list), axis=3)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,15))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    fig.suptitle(\"{} {} Model Sensitivity Score Trends\".format(MODEL_NAME, NUM_MODELS), fontsize= 30)\n",
    "\n",
    "    node_idx = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            node_subplot_dict = { \"Model_{}\".format(model_idx): sensitivty_score_nested_np[:,model_idx,node_idx] for model_idx in range(NUM_MODELS) }\n",
    "            node_subplot_dict[\"Rolling Window Index\"] = list(range(len(roll_win_aggreg_diff_nested_list)))\n",
    "            visual_df = pd.DataFrame(node_subplot_dict)\n",
    "\n",
    "            sns.lineplot(ax=col, x='Rolling Window Index', y='Sensitivity Scores', hue='Model', data=pd.melt(visual_df, ['Rolling Window Index'], value_name=\"Sensitivity Scores\", var_name=\"Model\"))\n",
    "            col.set_title(continents[node_idx])\n",
    "            col.legend().remove()\n",
    "            col.set_ylim([-70, 70])\n",
    "            node_idx += 1\n",
    "\n",
    "    filename = str(NUM_MODELS) + \"_models_sens_score_trends\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_model_sens_score_trends_lineplot(roll_win_aggreg_diff_nested_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Sensitvity Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_model_roll_win_sens_distribution(roll_win_aggreg_diff_nested_list):\n",
    "    \"\"\"\n",
    "    This function plots the 5x2 figure of sensitivity score distributions for each of the\n",
    "    10 continents. Each distribution will contain num_windows * num_models sensitivity scores.\n",
    "    Sensitivity scores are calculated by summing across row of 10x10 sensitivity array.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_aggreg_diff_nested_list: 10x10 sensitivity array, shape (num_windows, NUM_MODELS, 10, 10)\n",
    "    \"\"\"\n",
    "    sensitivty_score_nested_np = np.nansum(np.array(roll_win_aggreg_diff_nested_list), axis=3)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(35,16))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    fig.suptitle(\"{} {} Model Sensitivity Score Distributions\".format(MODEL_NAME, NUM_MODELS), fontsize=30)\n",
    "\n",
    "    pert_node_idx = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            country_sensitivity_scores = list(sensitivty_score_nested_np[:,:,pert_node_idx].flatten())\n",
    "            print(\"{} has {} sensitivity scores in distribution.\".format(continents[pert_node_idx], len(country_sensitivity_scores)))\n",
    "\n",
    "            visual_df = pd.DataFrame({\n",
    "                \"Sensitivity Score\": country_sensitivity_scores,\n",
    "            })\n",
    "\n",
    "            sns.histplot(ax=col, x='Sensitivity Score', data=visual_df, kde=True)\n",
    "            mode = st.mode(country_sensitivity_scores)\n",
    "            median = np.median(np.array(country_sensitivity_scores))\n",
    "            mean = np.mean(np.array(country_sensitivity_scores))\n",
    "            stddev = np.array(country_sensitivity_scores).std()\n",
    "            col.set_title(continents[pert_node_idx] + \"\\nMode \" + str(round(mode, 2)) + \", Mean: \" + str(round(mean, 2)) + \"\\nMedian: \" + str(round(median, 2)) + \", Std: \" + str(round(stddev, 2)))\n",
    "            col.set_xlim([-40, 40])\n",
    "            pert_node_idx += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = str(NUM_MODELS) + \"_models_sens_score_distrib\"\n",
    "    filename = \"{}_models_sens_score_distrib\".format(NUM_MODELS)\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_model_roll_win_sens_distribution(roll_win_aggreg_diff_nested_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit EV Distribution For Each Node on All Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivty_score_nested_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIT_NORMAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit EV distribution on each node on each window, save location and scale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_loc_params = []\n",
    "roll_win_scale_params = []\n",
    "for roll_win in range(len(sensitivty_score_nested_np)):\n",
    "    location_params = []\n",
    "    scale_params = []\n",
    "    for node_idx in range(10):\n",
    "        values = sensitivty_score_nested_np[roll_win,:,node_idx]\n",
    "        if FIT_NORMAL:\n",
    "            params = stats.norm.fit(values)\n",
    "        else:\n",
    "            # params = stats.gumbel_l.fit(values)\n",
    "            params = stats.gumbel_r.fit(values)\n",
    "        location_params.append(params[0])\n",
    "        scale_params.append(params[1])\n",
    "    \n",
    "    roll_win_loc_params.append(location_params)\n",
    "    roll_win_scale_params.append(scale_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_loc_params = np.array(roll_win_loc_params)\n",
    "roll_win_scale_params = np.array(roll_win_scale_params)\n",
    "print(roll_win_loc_params.shape)\n",
    "print(roll_win_scale_params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming arrays for plotting later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_win_fitted_means = roll_win_loc_params\n",
    "roll_win_fitted_stds = roll_win_scale_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Fitted EV Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for single_country_idx in range(10):\n",
    "    for single_window_idx in [0, 100, 200, 300, 400, 500]:\n",
    "        x = np.linspace(60, 0, 100)\n",
    "        if FIT_NORMAL:\n",
    "            plt.plot(x, stats.norm.pdf(x, roll_win_loc_params[single_window_idx, single_country_idx], roll_win_scale_params[single_window_idx, single_country_idx]), 'r-', label='normal pdf')\n",
    "        else:\n",
    "            # plt.plot(x, stats.gumbel_l.pdf(x, roll_win_loc_params[single_window_idx, single_country_idx], roll_win_scale_params[single_window_idx, single_country_idx]), 'r-', label='EV pdf')\n",
    "            plt.plot(x, stats.gumbel_r.pdf(x, roll_win_loc_params[single_window_idx, single_country_idx], roll_win_scale_params[single_window_idx, single_country_idx]), 'r-', label='EV pdf')\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        sns.histplot(x=sensitivty_score_nested_np[single_window_idx,:,single_country_idx].flatten(), stat=\"density\", label=continents[single_country_idx] + \" scores\")\n",
    "        \n",
    "        mean = np.mean(sensitivty_score_nested_np[single_window_idx,:,single_country_idx].flatten())\n",
    "        median = np.median(sensitivty_score_nested_np[single_window_idx,:,single_country_idx].flatten())\n",
    "        std = np.std(sensitivty_score_nested_np[single_window_idx,:,single_country_idx].flatten())\n",
    "\n",
    "        if FIT_NORMAL:\n",
    "            title = \"Normal Distribution fitted on {} on window {}\\nMean: {:.4f}, Median: {:.4f}, STD: {:.4f}\".format(continents[single_country_idx], single_window_idx, mean, median, std)\n",
    "            plt.title(title, fontsize=16)\n",
    "            plt.savefig(\"./normal_unfiltered_fit_{}_win{}.png\".format(continents[single_country_idx], single_window_idx), bbox_inches=\"tight\", facecolor=\"white\")\n",
    "        else:\n",
    "            title = \"EV Distribution fitted on {} on window {}\\nMean: {:.4f}, Median: {:.4f}, STD: {:.4f}\".format(continents[single_country_idx], single_window_idx, mean, median, std)\n",
    "            plt.title(title, fontsize=16)\n",
    "            plt.savefig(\"./ev_unfiltered_fit_{}_win{}.png\".format(continents[single_country_idx], single_window_idx), bbox_inches=\"tight\", facecolor=\"white\")\n",
    "        \n",
    "        # plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Model Average Sensitivity Score Trends After Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_model_average_sens_score_trend_after_filtering(roll_win_fitted_means, roll_win_fitted_stds):\n",
    "    \"\"\"\n",
    "    This function plots the 5x2 figure of average sensitivity score with a 1 STD interval above and below the\n",
    "    mean. Here, mean and std are the mean and std calculated above by fitting gumbel_L distribution on each\n",
    "    window for each model.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_fitted_means: shape (num_windows, 10)\n",
    "        - roll_win_fitted_stds: shape (num_windows, 10)\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,15))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    fig.suptitle(\"{} {} Model Average Fitted Sensitivity Score Mean\".format(MODEL_NAME, NUM_MODELS), fontsize= 30)\n",
    "    \n",
    "    node_idx = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            # all_model_country_scores is (num_models, num_roll_windows)\n",
    "            col.plot(roll_win_fitted_means[:, node_idx])\n",
    "            col.fill_between(list(range(len(roll_win_fitted_means))), (roll_win_fitted_means[:, node_idx] - roll_win_fitted_stds[:, node_idx]), (roll_win_fitted_means[:, node_idx] + roll_win_fitted_stds[:, node_idx]), color='b', alpha=.1)\n",
    "            col.set_title(continents[node_idx])\n",
    "            col.set_xlabel(\"Rolling Window Index\")\n",
    "            col.set_ylabel(\"Fitted Sensitivity Score\")\n",
    "            col.set_ylim([0, 40])\n",
    "            node_idx += 1\n",
    "\n",
    "    filename = \"{}_models_avg_sens_scores_unfiltered\".format(NUM_MODELS)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_model_average_sens_score_trend_after_filtering(roll_win_fitted_means, roll_win_fitted_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_plot_fitted_mu(roll_win_fitted_means):\n",
    "    \"\"\"\n",
    "    This function plots a violin plot with country on the x-axis and fitted sensitivity score mu parameter\n",
    "    on the y-axis. The figure is meant to show the different continent distribution on the same y-axis, \n",
    "    for comparison among continents after we rank the countries.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_fitted_means: [num_windows, 10] array\n",
    "    \"\"\"\n",
    "    roll_win_fitted_means_normalized = roll_win_fitted_means / roll_win_fitted_means.max()\n",
    "    continent_mu_parameters = []\n",
    "    corresp_country_name = []\n",
    "\n",
    "    continent_names = [\"\\n\".join(name.split(\" \")) for name in continents]\n",
    "    colors = sns.color_palette().as_hex()\n",
    "    medians = []\n",
    "\n",
    "    for node_idx in range(10):\n",
    "        continent_mu_parameters += list(roll_win_fitted_means_normalized[:,node_idx].flatten())\n",
    "        medians.append(np.median(roll_win_fitted_means_normalized[:,node_idx].flatten()))\n",
    "        corresp_country_name += [continent_names[node_idx]] * len(roll_win_fitted_means_normalized[:,node_idx].flatten())\n",
    "    \n",
    "    colors_sorted = [x for _,x in sorted(zip(medians, colors), reverse=True)]\n",
    "    continent_names_sorted = [x for _,x in sorted(zip(medians, continent_names), reverse=True)]\n",
    "\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Continent\": corresp_country_name,\n",
    "        \"Fitted Sensitivity Mu Parameter (Scaled to 0 - 1)\": continent_mu_parameters\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    sns.violinplot(data=visual_df, x=\"Continent\", y=\"Fitted Sensitivity Mu Parameter (Scaled to 0 - 1)\", \n",
    "                    order=continent_names_sorted, palette=colors_sorted)\n",
    "    plt.title(\"{} {} Models Fitted Sensitivity Mu Parameter Violin Plot (Unfiltered)\".format(MODEL_NAME, NUM_MODELS), fontsize=24)\n",
    "    \n",
    "    filename = \"{}_models_fitted_mu_violin_plot_unfiltered\".format(NUM_MODELS)\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin_plot_fitted_mu(roll_win_fitted_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_node_avg_sens_trend(roll_win_fitted_means):\n",
    "    \"\"\"\n",
    "    This function makes a figure showing node average sensitivity score over rolling windows.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_gumbel_means: shape (num_windows, 10)\n",
    "    \"\"\"\n",
    "    roll_win_fitted_means_normalized = roll_win_fitted_means / roll_win_fitted_means.max()\n",
    "    node_dict = { continents[node_idx]: roll_win_fitted_means_normalized[:, node_idx] for node_idx in range(10) }\n",
    "    node_dict[\"Rolling Window Index\"] = list(range(len(roll_win_fitted_means_normalized)))\n",
    "    visual_df = pd.DataFrame(node_dict)\n",
    "\n",
    "    plt.figure(figsize=(16, 8), dpi=80)\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    sns.lineplot(x='Rolling Window Index', y='Fitted Sensitivity Mu Parameter (Scaled 0 - 1)', hue='Continent', data=pd.melt(visual_df, ['Rolling Window Index'], value_name=\"Fitted Sensitivity Mu Parameter (Scaled 0 - 1)\", var_name=\"Continent\"))\n",
    "    plt.title(\"{} {} Models Fitted Sensitivity Mu Parameter Trend Unfiltered\".format(MODEL_NAME, NUM_MODELS), fontsize=24)\n",
    "    plt.xlabel('Rolling Window Idx')  \n",
    "    plt.ylabel('Fitted Sensitivity Mu Parameter (Scaled 0 - 1)')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    filename = \"{}_models_node_avg_sens_score_unfiltered\".format(NUM_MODELS)\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_node_avg_sens_trend(roll_win_fitted_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranks_by_sensitivty_score_mean(roll_win_aggreg_diff_nested_list):\n",
    "    \"\"\"\n",
    "    This function plots the continents rankings over rolling windows, ranked by sensitivity score \n",
    "    mean. This is not our final ranking, we just want to compare this to fitted distribution\n",
    "    rankings.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_aggreg_diff_nested_list: 10x10 sensitivity array, shape (num_windows, NUM_MODELS, 10, 10)\n",
    "    \"\"\"\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \n",
    "                'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "    sensitivty_score_nested_np = np.nansum(np.array(roll_win_aggreg_diff_nested_list), axis=3)\n",
    "    new_models_100_avg = np.nanmean(sensitivty_score_nested_np, axis=1)\n",
    "\n",
    "    # Compute ranks\n",
    "    ranks = np.zeros((len(new_models_100_avg),len(new_models_100_avg[0])))\n",
    "    for i in range(len(new_models_100_avg)):\n",
    "        array = new_models_100_avg[i,:]\n",
    "        temp = (-array).argsort()  # negative array if we want highest sensitivity to be 1st palce\n",
    "        ranks[i,:] = np.arange(len(array))[temp.argsort()] + 1  # Each position tells rank of model at that index\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    for i in range(10):\n",
    "        plt.plot(ranks[:,i], \"o-\", mfc=\"w\", label=continents[i], color=colors[i])\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Ranking by Sensitivity Score Mean Unfiltered\", fontsize=24)\n",
    "    plt.xlabel(\"Rolling Window Index\")\n",
    "    plt.ylabel(\"Ranking\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    filename = \"ranking_by_sensitivity_mean_unfiltered\"\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ranks_by_sensitivty_score_mean(roll_win_aggreg_diff_nested_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranks_by_fitted_mean(roll_win_fitted_means):\n",
    "    \"\"\"\n",
    "    This function plots the continents rankings over rolling windows, ranked by fitted gumbel \n",
    "    distribution mean.\n",
    "    \n",
    "    Args:\n",
    "        - roll_win_fitted_means: shape (num_windows, 10)\n",
    "    \"\"\"\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \n",
    "                'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "    # Compute ranks\n",
    "    ranks = np.zeros(roll_win_fitted_means.shape)\n",
    "    for roll_win in range(len(roll_win_fitted_means)):\n",
    "        array = roll_win_fitted_means[roll_win,:]\n",
    "        temp = (-array).argsort()  # Do negative arra for highest sensitivity 1st place\n",
    "        ranks[roll_win,:] = np.arange(len(array))[temp.argsort()] + 1  # Each position tells rank of model at that index\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    for i in range(10):\n",
    "        plt.plot(ranks[:,i], \"o-\", mfc=\"w\", label=continents[i], color=colors[i])\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Ranking by Fitted Distribution Mean Unfiltered\", fontsize=24)\n",
    "    plt.xlabel(\"Rolling Window Index\")\n",
    "    plt.ylabel(\"Ranking\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    filename = \"ranking_by_fitted_distrib_mean_unfiltered\"\n",
    "    plt.savefig(\"./\" + filename + '.png', bbox_inches='tight', facecolor='white')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ranks_by_fitted_mean(roll_win_fitted_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_for_sensitivity_rank_bump_chart(roll_win_fitted_means):\n",
    "    \"\"\"\n",
    "    If a saved csv file is needed to plot on a third-party website, this function saves the necessary lists\n",
    "    (fitted mu parameter list, rolling window index list, and region name list) needed to plot bump charts.\n",
    "    Website used to generate area bump chart: rawgraphs.io\n",
    "\n",
    "    Args:\n",
    "        - roll_win_fitted_means: shape (num_windows, 10)\n",
    "    \"\"\"\n",
    "    roll_win_fitted_means_normalized = roll_win_fitted_means / roll_win_fitted_means.max()\n",
    "    continent_name_list = []\n",
    "    window_idx_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for roll_window_idx in range(len(roll_win_fitted_means_normalized)):\n",
    "        for node_idx in range(10):\n",
    "            continent_name_list.append(continents[node_idx])\n",
    "            window_idx_list.append(roll_window_idx)\n",
    "            score_list.append(roll_win_fitted_means_normalized[roll_window_idx, node_idx])\n",
    "    \n",
    "    bump_chart_df = pd.DataFrame({\n",
    "        \"Geographical Region\": continent_name_list,\n",
    "        \"Rolling Window Index\": window_idx_list,\n",
    "        \"Fitted Mu\": score_list\n",
    "    })\n",
    "    bump_chart_df.to_csv(\"./bump_chart_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv_for_sensitivity_rank_bump_chart(roll_win_fitted_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Plot Between Flight Rankings and Fitted Mu Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv19 = np.load(\"./datasets/10_continents_dataset_v19_node_pert.npz\")\n",
    "datasetv19.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daywise_outgoing_flights = np.nansum(datasetv19['flight_matrix_unscaled'], axis=1)\n",
    "daywise_outgoing_flights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change flight counts from days to rolling windows by summing across recursive prediction rolling window. Length of rolling window is 30 + WINDOW_LENGTH, because model takes 1 window and then predicts 30 days, so it takes 30 + WINDOW_SIZE days of flight data in total for 1 rolling window.\n",
    "\n",
    "len(daywise_outgoing_flights) - 30 - WINDOW_SIZE - WINDOW_SIZE is because a rolling window is 30 + WINDOW_SIZE in length, and subtracting the second WINDOW_SIZE accounts for the dataloader creating windows from days and having WINDOW_SIZE less days than windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollwin_outgoing_flights = [daywise_outgoing_flights[idx: idx + 30 + WINDOW_SIZE, :].sum(axis=0) for idx in range(len(daywise_outgoing_flights) - 30 - WINDOW_SIZE - WINDOW_SIZE)]\n",
    "rollwin_outgoing_flights = np.array(rollwin_outgoing_flights)\n",
    "rollwin_outgoing_flights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if want to log10 transform flights\n",
    "# rollwin_outgoing_flights = np.log10(rollwin_outgoing_flights, where=rollwin_outgoing_flights != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Fitted Distribution Mu Parameter against number of flights Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_means = []\n",
    "flight_numbers = []\n",
    "continents_name = []\n",
    "roll_win_fitted_means_normalized = roll_win_fitted_means / roll_win_fitted_means.max()\n",
    "\n",
    "for i in range(10):\n",
    "    fitted_means += list(roll_win_fitted_means_normalized[:,i])\n",
    "    flight_numbers += list(rollwin_outgoing_flights[:,i])\n",
    "    continents_name += [continents[i]] * len(roll_win_fitted_means_normalized)\n",
    "\n",
    "visual_df = pd.DataFrame({\n",
    "    \"Normalized μ Value\": fitted_means,\n",
    "    \"Summed Outgoing Flights Over Rolling Window\": flight_numbers,\n",
    "    \"Continent\": continents_name\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "sns.scatterplot(data=visual_df, y=\"Normalized μ Value\", x=\"Summed Outgoing Flights Over Rolling Window\", hue=\"Continent\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"./{}_models_fitted_mu_vs_flights_scatterplot.png\".format(NUM_MODELS), bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Fitted Distribution Mu Parameter Against Num Cases Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases_matrix = datasetv19['feature_matrix_smooth'][:,:,1]\n",
    "print(num_cases_matrix.max())\n",
    "print(num_cases_matrix.min())\n",
    "print(num_cases_matrix.mean())\n",
    "num_cases_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale back up to normal scale to avoid summing log values\n",
    "num_cases_matrix = np.power(10, num_cases_matrix, where=num_cases_matrix != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollwin_ncases = [num_cases_matrix[idx: idx + 30 + WINDOW_SIZE, :].sum(axis=0) for idx in range(len(num_cases_matrix) - 30 - WINDOW_SIZE - WINDOW_SIZE)]\n",
    "rollwin_ncases = np.array(rollwin_ncases)\n",
    "rollwin_ncases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if want to log10 transform summation back down to log10 scale\n",
    "# rollwin_ncases = np.log10(rollwin_ncases, where=rollwin_ncases != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mus = []\n",
    "ncases = []\n",
    "continents_name = []\n",
    "\n",
    "for i in range(10):\n",
    "    fitted_mus += list(roll_win_fitted_means_normalized[:,i])\n",
    "    ncases += list(rollwin_ncases[:,i])\n",
    "    continents_name += [continents[i]] * len(roll_win_fitted_means_normalized)\n",
    "\n",
    "print(len(fitted_mus))\n",
    "print(len(ncases))\n",
    "print(len(continents_name))\n",
    "\n",
    "visual_df = pd.DataFrame({\n",
    "    \"Fitted Distribution Sensitivity (Scaled to 0 - 1)\": fitted_mus,\n",
    "    \"Summed Cases Over Rolling Window\": ncases,\n",
    "    \"Continents\": continents_name\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "sns.scatterplot(data=visual_df, x=\"Summed Cases Over Rolling Window\", y=\"Normalized μ Value\", hue=\"Continents\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"./{}_models_fitted_mu_vs_ncases_scatterplot.png\".format(NUM_MODELS), bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c3ec5cb0d81e7b9f9908a53ca28aa4318265e5d52f388cac911a9765dd2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
