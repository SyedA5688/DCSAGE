{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters and Save Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINENTS = [\"Africa\", \"North America\", \"South America\", \"Oceania\", \"Eastern Europe\", \"Western Europe\", \"Middle East\", \"South Asia\", \"Southeast-East Asia\", \"Central Asia\"]\n",
    "WINDOW_SIZE = 7\n",
    "RECURSIVE_WINDOW_LENGTH = 30\n",
    "NODES_TO_PERTURB = 5  # 3 means that 1, 2, or 3 nodes might be perturbed\n",
    "MODEL_IDXS = list(range(10))  # list(range(80, 100))\n",
    "SAVE_PATH = \"./runs/2022-04-16-00_41_22/models{}-{}\".format(MODEL_IDXS[0], MODEL_IDXS[-1])\n",
    "\n",
    "SENSITIVITY_ORDER = [\"Western Europe\", \"North America\", \"Middle East\", \"Eastern Europe\", \"Southeast-East Asia\", \"Oceania\", \"South America\", \"South Asia\", \"Africa\", \"Central Asia\"]\n",
    "SENSITIVITY_ORDER_IDX = [CONTINENTS.index(SENSITIVITY_ORDER[i]) for i in range(len(SENSITIVITY_ORDER))]\n",
    "PERTURBATION_STEPS = [-0.25, -0.5, -0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Combinations of Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perturbations = []\n",
    "\n",
    "# Create all combinations of perturbation policies\n",
    "for num_nodes_to_pert in range(1, NODES_TO_PERTURB + 1):  # 3 means 1, 2, then 3 nodes are perturbed at once\n",
    "    combinations_list = [p for p in itertools.product(PERTURBATION_STEPS, repeat=num_nodes_to_pert)]\n",
    "    # print(combinations_list, \"\\n\", len(combinations_list), \"\\n\")\n",
    "\n",
    "    for combo_tuple in combinations_list:\n",
    "        # length of combo tuple = num_nodes to perturb\n",
    "        perturb_node_steps = [0,0,0,0,0,0,0,0,0,0]\n",
    "        for idx, val in enumerate(combo_tuple):\n",
    "            perturb_node_steps[idx] = val\n",
    "        # print(perturb_node_steps)\n",
    "\n",
    "        all_perturbations.append(perturb_node_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_perturbations))\n",
    "all_perturbations[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perturbations = np.array(all_perturbations)\n",
    "all_perturbations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved prediction array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prediction_array = np.load(os.path.join(SAVE_PATH, \"models_{}-{}_predictions.npy\".format(MODEL_IDXS[0], MODEL_IDXS[-1])))\n",
    "total_prediction_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from log scale to real number scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prediction_array = np.power(10, total_prediction_array, where=total_prediction_array != 0)\n",
    "total_prediction_array.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10, 364, 523, 30, 10) = (num_models, num_dataloaders, num_rolling_windows, recursive_pred_len, 10 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unperturbed_predictions = total_prediction_array[:,0]\n",
    "print(unperturbed_predictions.shape)\n",
    "\n",
    "perturb_combo_predictions = total_prediction_array[:,1:]\n",
    "print(perturb_combo_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sum of Difference On Each Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_window_sum_differences = np.zeros((perturb_combo_predictions.shape[0], perturb_combo_predictions.shape[1], perturb_combo_predictions.shape[2]))\n",
    "dataloader_window_sum_differences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains code which loops over windows and then dataloaders each representing a different perturbation \n",
    "combination.\n",
    "Steps:\n",
    "1. Compute global sum of COVID cases on each day in recursive prediction window (30 days) for unperturbed and perturbed\n",
    "2. Subtract perturbed - unperturbed on each day, sum up difference across 30 days\n",
    "3. Sum of difference is obtained for each window, save into np array\n",
    "\"\"\"\n",
    "for model_idx in range(dataloader_window_sum_differences.shape[0]):\n",
    "    for window_idx in range(dataloader_window_sum_differences.shape[2]):\n",
    "        # Sum nodes to calculate global cases for each of the 30 days of unperturbed recursive prediction\n",
    "        unpert_global_cases_sum = unperturbed_predictions[:, window_idx].sum(axis=-1)  # Shape (10, 30)\n",
    "        \n",
    "        for dataloader_idx in range(dataloader_window_sum_differences.shape[1]):\n",
    "            # Sum nodes to calculate global cases for each of the 30 days of perturbed recursive prediction\n",
    "            pert_global_cases_sum = perturb_combo_predictions[:, dataloader_idx, window_idx].sum(axis=-1)  # Shape (10, 30,)\n",
    "            \n",
    "            # Subtract perturbed - unperturbed, shape (10, 30,)\n",
    "            differences = pert_global_cases_sum - unpert_global_cases_sum\n",
    "            differences = np.abs(differences)  # Take absolute difference\n",
    "            window_summed_difference = differences.sum(axis=-1)  # Sum up across 30 days, shape (10,)\n",
    "            \n",
    "            # Place into dataloader_window_sum_differences for later computation\n",
    "            dataloader_window_sum_differences[:, dataloader_idx, window_idx] = window_summed_difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloader_window_sum_differences.shape)\n",
    "# dataloader_window_sum_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Across Model and Window Dimensions\n",
    "For now, assuming that aggregation will be mean. Take mean summed difference across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_window_difference_mean = dataloader_window_sum_differences.mean(axis=0)\n",
    "model_window_difference_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then take mean across window dimension, calculate standard deviation as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_difference_mean = model_window_difference_mean.mean(axis=-1)\n",
    "window_difference_mean_normalized = window_difference_mean / window_difference_mean.max()\n",
    "window_difference_std = model_window_difference_mean.std(axis=-1)\n",
    "window_difference_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perturbations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet_dict = {}\n",
    "for idx in range(10):\n",
    "    spreadsheet_dict[SENSITIVITY_ORDER[idx]] = all_perturbations[:, idx]\n",
    "spreadsheet_dict[\"Mean Model Mean Window Summed Difference\"] = window_difference_mean\n",
    "spreadsheet_dict[\"Mean Model Mean Window Summed Difference Normalized\"] = window_difference_mean_normalized\n",
    "spreadsheet_dict[\"Standard Deviation Across Windows\"] = window_difference_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet_df = pd.DataFrame(spreadsheet_dict)\n",
    "spreadsheet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to excel file\n",
    "spreadsheet_df.to_excel(os.path.join(SAVE_PATH, \"models_{}-{}_spreadsheet_unsigned.xlsx\".format(MODEL_IDXS[0], MODEL_IDXS[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Perturbation Policy Magnitude versus Policy Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_policy_sums = all_perturbations.sum(axis=-1)\n",
    "perturbation_policy_sums.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_difference_mean_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy_magnitude_vs_impact(perturbation_policy_sums, window_difference_mean_normalized):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=perturbation_policy_sums, y=window_difference_mean_normalized)\n",
    "    plt.title(\"Perturbation Policy Magnitude Sum vs Impact\")\n",
    "    plt.xlabel(\"Perturbation Policy Summed Magnitude\")\n",
    "    plt.ylabel(\"Policy Impact\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"policy_magnitude_vs_impact.png\"), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policy_magnitude_vs_impact(perturbation_policy_sums, window_difference_mean_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_sums_df = pd.DataFrame({\n",
    "    \"Policy Magnitude Sum\": perturbation_policy_sums,\n",
    "    \"Policy Impact\": window_difference_mean_normalized\n",
    "})\n",
    "policy_sums_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_sums_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_sums_averages = policy_sums_df.groupby([\"Policy Magnitude Sum\"], as_index=False).mean()\n",
    "policy_sums_averages.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to excel\n",
    "policy_sums_averages.to_excel(os.path.join(SAVE_PATH, \"models_{}-{}_avg_impact_per_policy_sum.xlsx\".format(MODEL_IDXS[0], MODEL_IDXS[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy_magnitude_vs_impact_averages(policy_sums_averages_df):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(data=policy_sums_averages_df, x=\"Policy Magnitude Sum\", y=\"Policy Impact\")\n",
    "    plt.title(\"Perturbation Policy Magnitude Sum vs Average Impact\")\n",
    "    plt.xlabel(\"Perturbation Policy Summed Magnitude\")\n",
    "    plt.ylabel(\"Average Policy Impact\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"policy_magnitude_vs_average_impact.png\"), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policy_magnitude_vs_impact_averages(policy_sums_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Unperturbed vs Most/Medium/Least Impactful Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_window = 380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Trends for Unperturbed cases, strong policy, medium policy, and weak policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_10_models_unpert_cases(unperturbed_predictions):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    visual_dict = { \"Model {}\".format(idx): unperturbed_predictions[idx,chosen_window,:,:].sum(axis=-1) for idx in range(10) }  # Global case trends for 10 models\n",
    "    visual_dict[\"Day Index\"] = list(range(30))\n",
    "    visual_df = pd.DataFrame(visual_dict)\n",
    "    sns.lineplot(data=pd.melt(visual_df, ['Day Index'], value_name=\"Unperturbed Global Cases\", var_name=\"Model\"), x=\"Day Index\", y=\"Unperturbed Global Cases\", hue=\"Model\")\n",
    "\n",
    "    plt.title(\"Global Unperturbed Case Predictions on Last Window\")\n",
    "    # plt.xlabel(\"Day Index\")\n",
    "    # plt.ylabel(\"Policy Impact\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"last_window_unpert_global_case_trends.png\"), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_10_models_unpert_cases(unperturbed_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_10_models_policy_cases(perturb_combo_predictions, policy_idx, policy_desc_str):\n",
    "    # Index of most impactful policy: 356, [-0.75, -0.75, -0.75, -0.25, -0.25, 0...0]\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    visual_dict = { \"Model {}\".format(idx): perturb_combo_predictions[idx,policy_idx,chosen_window,:,:].sum(axis=-1) for idx in range(10) }  # Global case trends for 10 models\n",
    "    visual_dict[\"Day Index\"] = list(range(30))\n",
    "    visual_df = pd.DataFrame(visual_dict)\n",
    "    sns.lineplot(data=pd.melt(visual_df, ['Day Index'], value_name=\"Global Cases\", var_name=\"Model\"), x=\"Day Index\", y=\"Global Cases\", hue=\"Model\")\n",
    "\n",
    "    plt.title(\"Global Case Predictions on Last Window under {} Impactful Polcy\".format(policy_desc_str))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"last_window_{}_impactful_policy_global_case_trends.png\".format(policy_desc_str)), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_10_models_policy_cases(perturb_combo_predictions, 356, \"Most\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_10_models_policy_cases(perturb_combo_predictions, 170, \"Medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_10_models_policy_cases(perturb_combo_predictions, 0, \"Least\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Each model trend figure with 4 curves:\n",
    "Unperturbed, Most Impactful Policy, Medium Impact Policy, Least Impactful Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset object and use it to plot initial 7 days that start off recursive predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Covid10CountriesPerturbedDataset(Dataset):\n",
    "    def __init__(self, dataset_npz_path, SENSITIVITY_ORDER_IDX, window_size=7, data_split=\"entire-dataset-smooth\", avg_graph_structure=False, perturb_node_steps=[-0.25,0,0,0,0,0,0,0,0,0]):\n",
    "        ###########\n",
    "        # Load data\n",
    "        ###########\n",
    "        if data_split == \"entire-dataset-smooth\" and not avg_graph_structure:\n",
    "            feature_matrix = np.load(dataset_npz_path)[\"feature_matrix_smooth\"]\n",
    "            flight_matrix = np.load(dataset_npz_path)[\"flight_matrix_log10_scaled\"]\n",
    "        elif data_split == \"entire-dataset-smooth\" and avg_graph_structure:\n",
    "            feature_matrix = np.load(dataset_npz_path)[\"feature_matrix_smooth\"]\n",
    "            flight_matrix = np.load(dataset_npz_path)[\"flight_matrix_unscaled\"]\n",
    "        else:\n",
    "            raise RuntimeError(\"Unknown dataset split selected\")\n",
    "        \n",
    "        assert feature_matrix.shape[0] == flight_matrix.shape[0], \"Node feature and edge attribute matrices do not match\"\n",
    "        \n",
    "        ################################################################\n",
    "        # Perturb chosen country by deleting incoming and outgoing edges\n",
    "        ################################################################\n",
    "        for node_idx, perturb_step in zip(SENSITIVITY_ORDER_IDX, perturb_node_steps):\n",
    "            flight_matrix[:, node_idx, :] *= (1 + perturb_step)\n",
    "            flight_matrix[:, :, node_idx] *= (1 + perturb_step)\n",
    "\n",
    "        self.feature_matrix = feature_matrix\n",
    "        self.flight_matrix = flight_matrix\n",
    "\n",
    "        ###############################\n",
    "        # Create sliding window dataset\n",
    "        ###############################\n",
    "        all_window_node_feat = []\n",
    "        all_window_edge_attr = []\n",
    "        all_window_edge_idx = []\n",
    "        all_window_labels = []\n",
    "        \n",
    "        for day_idx in range(0, len(feature_matrix) - window_size):\n",
    "            window_node_feat = []\n",
    "            window_edge_idx = []\n",
    "            window_edge_attr = []\n",
    "\n",
    "            for sub_day in range(day_idx, day_idx + window_size):\n",
    "                node_data = feature_matrix[sub_day]\n",
    "\n",
    "                edges_idx_array = np.full((2, 100), -1)\n",
    "                edges_attr_array = np.full((100), -1).astype(np.float32)\n",
    "                \n",
    "                if avg_graph_structure:\n",
    "                    # Calculate smoothened graph structure across window\n",
    "                    smoothened_window_flight_matrix = flight_matrix[day_idx: day_idx + window_size].mean(axis=0)  # Shape [10, 10]\n",
    "                    # Log10 scale now that adjacency is averaged\n",
    "                    for row in range(len(smoothened_window_flight_matrix)):\n",
    "                        for col in range(len(smoothened_window_flight_matrix[row])):\n",
    "                            if smoothened_window_flight_matrix[row][col] > 0:\n",
    "                                smoothened_window_flight_matrix[row][col] = np.log10(smoothened_window_flight_matrix[row][col])\n",
    "                    \n",
    "                    edge_idx = 0\n",
    "                    for row in range(len(smoothened_window_flight_matrix)):\n",
    "                        for col in range(len(smoothened_window_flight_matrix[row])):\n",
    "                            if smoothened_window_flight_matrix[row][col] > 0:\n",
    "                                edges_idx_array[0][edge_idx] = row  # row is source node\n",
    "                                edges_idx_array[1][edge_idx] = col  # col is dest node\n",
    "                                edges_attr_array[edge_idx] = smoothened_window_flight_matrix[row][col]\n",
    "                                edge_idx += 1\n",
    "                else:\n",
    "                    edge_idx = 0\n",
    "                    for row in range(len(flight_matrix[sub_day])):\n",
    "                        for col in range(len(flight_matrix[sub_day][row])):\n",
    "                            if flight_matrix[sub_day][row][col] > 0:\n",
    "                                edges_idx_array[0][edge_idx] = row\n",
    "                                edges_idx_array[1][edge_idx] = col\n",
    "                                edges_attr_array[edge_idx] = flight_matrix[sub_day][row][col]\n",
    "                                edge_idx += 1\n",
    "                \n",
    "                edges_attr_array = np.expand_dims(edges_attr_array, axis=-1)\n",
    "\n",
    "                window_node_feat.append(np.expand_dims(node_data, axis=0))\n",
    "                window_edge_idx.append(np.expand_dims(edges_idx_array, axis=0))\n",
    "                window_edge_attr.append(np.expand_dims(edges_attr_array, axis=0))\n",
    "            \n",
    "            window_node_feat = np.concatenate(window_node_feat, axis=0)  # shape (14, 10, 3)\n",
    "            window_edge_idx = np.concatenate(window_edge_idx, axis=0)  # Shape (14, 2, *num_edges=100)\n",
    "            window_edge_attr = np.concatenate(window_edge_attr, axis=0)  # Shape (14, *num_edges=100, 1)\n",
    "            window_labels = feature_matrix[day_idx + window_size, :, 1]  # Shape (10)\n",
    "\n",
    "            all_window_node_feat.append(np.expand_dims(window_node_feat, axis=0))\n",
    "            all_window_edge_attr.append(np.expand_dims(window_edge_attr, axis=0))\n",
    "            all_window_edge_idx.append(np.expand_dims(window_edge_idx, axis=0))\n",
    "            all_window_labels.append(np.expand_dims(window_labels, axis=0))\n",
    "        \n",
    "        self.all_window_node_feat = np.concatenate(all_window_node_feat, axis=0)\n",
    "        self.all_window_edge_attr = np.concatenate(all_window_edge_attr, axis=0)\n",
    "        self.all_window_edge_idx = np.concatenate(all_window_edge_idx, axis=0)\n",
    "        self.all_window_labels = np.concatenate(all_window_labels, axis=0)  # shape (dataset_len, 10)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_window_labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        window_node_feat = self.all_window_node_feat[index].astype(np.float32)  # shape (14, 10, 3)\n",
    "        window_edge_idx = self.all_window_edge_idx[index]  # shape (14, 2, *num_edges=100)\n",
    "        window_edge_idx = torch.LongTensor(window_edge_idx)\n",
    "        window_edge_attr = self.all_window_edge_attr[index]  # shape (14, *num_edges=100, 1)\n",
    "        window_labels = self.all_window_labels[index]  # shape (10)\n",
    "        \n",
    "        return window_node_feat[:,:,1:2], window_edge_idx, window_edge_attr, window_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_four_trend_curve_per_model(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict):\n",
    "\n",
    "    unpert_dataset = Covid10CountriesPerturbedDataset(\n",
    "        dataset_npz_path=\"./10_continents_dataset_v19_node_pert.npz\",\n",
    "        SENSITIVITY_ORDER_IDX=SENSITIVITY_ORDER_IDX,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        data_split=\"entire-dataset-smooth\",\n",
    "        avg_graph_structure=False,\n",
    "        perturb_node_steps=[0,0,0,0,0,0,0,0,0,0]\n",
    "    )\n",
    "    assert len(unpert_dataset.all_window_edge_attr) - WINDOW_SIZE - RECURSIVE_WINDOW_LENGTH == unperturbed_predictions.shape[1], \"Inconsistent window counts.\"\n",
    "\n",
    "    # Create first window cases, keep np.nan at end so does not show up on plot\n",
    "    first_window_cases = np.zeros((RECURSIVE_WINDOW_LENGTH + WINDOW_SIZE, 10))\n",
    "    first_window_cases[:WINDOW_SIZE,:] = unpert_dataset.all_window_node_feat[chosen_window,:,:,1]\n",
    "    first_window_cases[first_window_cases == 0] = np.nan\n",
    "    first_window_cases = np.power(10, first_window_cases, where=first_window_cases != 0)\n",
    "    # print(first_window_cases.sum(axis=-1))\n",
    "    first_window_cases = first_window_cases.sum(axis=-1)\n",
    "\n",
    "    # Index of most impactful policy: 356, [-0.75, -0.75, -0.75, -0.25, -0.25, 0...0]\n",
    "    for model_index in range(len(MODEL_IDXS)):\n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        plt.figure(figsize=(10,8))\n",
    "        visual_dict = {}\n",
    "        for key, val in policy_indices_dict.items():\n",
    "            predictions = perturb_combo_predictions[model_index,key,chosen_window,:,:].sum(axis=-1)\n",
    "            predictions = np.pad(predictions, (WINDOW_SIZE, 0), \"constant\", constant_values=(0,0))\n",
    "            predictions[predictions == 0] = np.nan\n",
    "            visual_dict[\"{} Impactful Policy\".format(val)] = predictions\n",
    "        unpert_preds = unperturbed_predictions[model_index,chosen_window,:,:].sum(axis=-1)\n",
    "        unpert_preds = np.pad(unpert_preds, (WINDOW_SIZE, 0), \"constant\", constant_values=(0,0))\n",
    "        unpert_preds[unpert_preds == 0] = np.nan\n",
    "        visual_dict[\"Unperturbed Predictions\"] = unpert_preds\n",
    "        visual_dict[\"Day Index\"] = list(range(RECURSIVE_WINDOW_LENGTH + WINDOW_SIZE))\n",
    "        visual_dict[\"Starting Input\"] = first_window_cases\n",
    "        visual_df = pd.DataFrame(visual_dict)\n",
    "\n",
    "        sns.lineplot(data=pd.melt(visual_df, ['Day Index'], value_name=\"Global Cases\", var_name=\"Varying Policies\"), x=\"Day Index\", y=\"Global Cases\", hue=\"Varying Policies\", palette=[\"green\", \"blue\", \"red\", \"black\", \"blue\"], sizes=[2,2,2,3.5,3.5], size=\"Varying Policies\")\n",
    "\n",
    "        plt.title(\"Model {} Global Cases Under Varying Policies\".format(model_index))\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.savefig(os.path.join(SAVE_PATH, \"varying_policy_trends_last_window_model_{}.png\".format(model_index)), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Need to change policy indices to select most impactful, medium impact, and least impactful policy\n",
    "policy_indices_dict = {\n",
    "    118: \"Most\",\n",
    "    283: \"Medium\",\n",
    "    0: \"Least\"\n",
    "}\n",
    "plot_four_trend_curve_per_model(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Continent-wise Change in Predicted Cases\n",
    "Goal is to investigate why there are more positive models than in node perturbation. </br>\n",
    "Theory is that multiple nodes are being perturbed, some countries go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unperturbed_predictions.shape)\n",
    "print(perturb_combo_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_model_node_wise_change_in_prediction(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict, model_idx):\n",
    "    \"\"\"\n",
    "    This function creates 3 figures using the given model's predictions, each figure correspond to one policy\n",
    "    (most, medium, or least impactful) and will have 20 lines: 10 solid line will be the unperturbed predictions,\n",
    "    and the dashed lines will be the cases forecasted under the given policy.\n",
    "\n",
    "    These figures are meant to show node-wise changes in cases based on the policy, and how the changes in cases\n",
    "    might be summed together. It is also meant to investigate why there are more positive models than in node\n",
    "    perturbation.\n",
    "    \"\"\"\n",
    "    plot_save_path = os.path.join(SAVE_PATH, \"one_model_policy_node_wise_changes\")\n",
    "    if not os.path.exists(plot_save_path):\n",
    "        os.mkdir(plot_save_path)\n",
    "\n",
    "    unpert_dataset = Covid10CountriesPerturbedDataset(\n",
    "        dataset_npz_path=\"./10_continents_dataset_v19_node_pert.npz\",\n",
    "        SENSITIVITY_ORDER_IDX=SENSITIVITY_ORDER_IDX,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        data_split=\"entire-dataset-smooth\",\n",
    "        avg_graph_structure=False,\n",
    "        perturb_node_steps=[0,0,0,0,0,0,0,0,0,0]\n",
    "    )\n",
    "    assert len(unpert_dataset.all_window_edge_attr) - WINDOW_SIZE - RECURSIVE_WINDOW_LENGTH == unperturbed_predictions.shape[1], \"Inconsistent window counts.\"\n",
    "\n",
    "    # Create first window cases, keep np.nan at end so does not show up on plot\n",
    "    first_window_cases = np.zeros((RECURSIVE_WINDOW_LENGTH + WINDOW_SIZE, 10))\n",
    "    first_window_cases[:WINDOW_SIZE,:] = unpert_dataset.all_window_node_feat[chosen_window,:,:,1]\n",
    "    first_window_cases[first_window_cases == 0] = np.nan\n",
    "    first_window_cases = np.power(10, first_window_cases, where=first_window_cases != 0)\n",
    "    \n",
    "    for key, val in policy_indices_dict.items():\n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        plt.figure(figsize=(16,12))\n",
    "        visual_dict_unpert = {}\n",
    "        visual_dict_pert = {}\n",
    "        visual_dict_start_input = {}\n",
    "        for node_idx in range(len(CONTINENTS)):\n",
    "            unpert_preds = unperturbed_predictions[model_idx,chosen_window,:,node_idx]\n",
    "            unpert_preds = np.pad(unpert_preds, (WINDOW_SIZE, 0), \"constant\", constant_values=(0,0))\n",
    "            unpert_preds[unpert_preds == 0] = np.nan\n",
    "            visual_dict_unpert[CONTINENTS[node_idx] + \" Unperturbed\"] = unpert_preds\n",
    "\n",
    "            pert_preds = perturb_combo_predictions[model_idx,key,chosen_window,:,node_idx]\n",
    "            pert_preds = np.pad(pert_preds, (WINDOW_SIZE, 0), \"constant\", constant_values=(0,0))\n",
    "            pert_preds[pert_preds == 0] = np.nan\n",
    "            visual_dict_pert[CONTINENTS[node_idx] + \" Perturbed\"] = pert_preds\n",
    "        \n",
    "        for node_idx in range(len(CONTINENTS)):\n",
    "            visual_dict_start_input[\"{} Starting Input\".format(CONTINENTS[node_idx])] = first_window_cases[:,node_idx]\n",
    "        visual_dict_unpert[\"Day Index\"] = list(range(RECURSIVE_WINDOW_LENGTH + WINDOW_SIZE))\n",
    "        visual_dict_pert[\"Day Index\"] = list(range(RECURSIVE_WINDOW_LENGTH + WINDOW_SIZE))\n",
    "        visual_dict_start_input[\"Day Index\"] = list(range(RECURSIVE_WINDOW_LENGTH + WINDOW_SIZE))\n",
    "\n",
    "        visual_df_unpert = pd.DataFrame(visual_dict_unpert)\n",
    "        visual_df_pert = pd.DataFrame(visual_dict_pert)\n",
    "        visual_df_start_input = pd.DataFrame(visual_dict_start_input)\n",
    "        sns.lineplot(data=pd.melt(visual_df_unpert, ['Day Index'], value_name=\"Cases\", var_name=\"Continent\"), x=\"Day Index\", y=\"Cases\", hue=\"Continent\")\n",
    "        sns.lineplot(data=pd.melt(visual_df_pert, ['Day Index'], value_name=\"Cases\", var_name=\"Continent\"), x=\"Day Index\", y=\"Cases\", hue=\"Continent\", linestyle=\"dashed\")\n",
    "        sns.lineplot(data=pd.melt(visual_df_start_input, ['Day Index'], value_name=\"Cases\", var_name=\"Continent\"), x=\"Day Index\", y=\"Cases\", hue=\"Continent\", linestyle=\"solid\")\n",
    "\n",
    "        plt.title(\"Model {} {} Impactful Policy Continent-Wise Changes\".format(model_idx, val), fontsize=20)\n",
    "        plt_legend_lines = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)).get_lines()\n",
    "        for i in range(10, 20):\n",
    "            plt_legend_lines[i].set_linestyle(\"--\")\n",
    "        plt.savefig(os.path.join(plot_save_path, \"model_{}_{}_policy_node_wise_change.png\".format(model_idx, val)), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_model_node_wise_change_in_prediction(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict, model_idx=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_three_trend_unsigned_policy_impact_per_model(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict):\n",
    "    # Index of most impactful policy: 356, [-0.75, -0.75, -0.75, -0.25, -0.25, 0...0]\n",
    "\n",
    "    for model_index in range(len(MODEL_IDXS)):\n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        plt.figure(figsize=(10,8))\n",
    "        visual_dict = {}\n",
    "        for key, val in policy_indices_dict.items():\n",
    "            visual_dict[\"{} Impactful Policy\".format(val)] = np.abs(perturb_combo_predictions[model_index,key,chosen_window,:,:].sum(axis=-1) - unperturbed_predictions[model_index,chosen_window,:,:].sum(axis=-1))\n",
    "        visual_dict[\"Day Index\"] = list(range(30))\n",
    "        visual_df = pd.DataFrame(visual_dict)\n",
    "        sns.lineplot(data=pd.melt(visual_df, ['Day Index'], value_name=\"Impact on Cases\", var_name=\"Varying Policies\"), x=\"Day Index\", y=\"Impact on Cases\", hue=\"Varying Policies\", palette=[\"green\", \"blue\", \"red\"], sizes=[2,2,2], size=\"Varying Policies\")\n",
    "\n",
    "        plt.title(\"Model {} Impact on Cases Under Varying Policies\".format(model_index))\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.savefig(os.path.join(SAVE_PATH, \"three_policy_unsigned_impact_trends_model_{}.png\".format(model_index)), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_three_trend_unsigned_policy_impact_per_model(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unperturbed_predictions.shape)\n",
    "print(perturb_combo_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_three_trend_unsigned_policy_impact_average_all_models(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict):\n",
    "    # Index of most impactful policy: 356, [-0.75, -0.75, -0.75, -0.25, -0.25, 0...0]\n",
    "\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(10,8))\n",
    "    visual_dict = {}\n",
    "    for key, val in policy_indices_dict.items():\n",
    "        visual_dict[\"{} Impactful Policy\".format(val)] = np.abs(perturb_combo_predictions[:,key,chosen_window,:,:].sum(axis=-1).mean(axis=0) - unperturbed_predictions[:,chosen_window,:,:].sum(axis=-1).mean(axis=0))\n",
    "    visual_dict[\"Day Index\"] = list(range(30))\n",
    "    visual_df = pd.DataFrame(visual_dict)\n",
    "    sns.lineplot(data=pd.melt(visual_df, ['Day Index'], value_name=\"Average Impact on Cases\", var_name=\"Varying Policies\"), x=\"Day Index\", y=\"Average Impact on Cases\", hue=\"Varying Policies\", palette=[\"green\", \"blue\", \"red\"], sizes=[2,2,2], size=\"Varying Policies\")\n",
    "\n",
    "    plt.title(\"Average Model Impact on Cases Under Varying Policies\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"three_policy_unsigned_impact_trends_all_models_avg.png\"), facecolor=\"white\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_three_trend_unsigned_policy_impact_average_all_models(unperturbed_predictions, perturb_combo_predictions, policy_indices_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c3ec5cb0d81e7b9f9908a53ca28aa4318265e5d52f388cac911a9765dd2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
