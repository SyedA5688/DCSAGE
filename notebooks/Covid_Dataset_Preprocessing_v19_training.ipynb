{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = np.load(\"./continents_new_features.npz\")[\"arr_0\"]\n",
    "features_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_matrix = np.load(\"./continents_flight_zero_diag.npz\")[\"arr_0\"]\n",
    "flights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_matrix[600,:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = [\"Africa\", \"North America\", \"South America\", \"Oceania\", \"Eastern Europe\", \"Western Europe\", \"Middle East\", \"South Asia\", \"Southeast-East Asia\", \"Central Asia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync two matrices\n",
    "March 1st, 2020 to September 30th, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix[616,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_matrix[424,0:10,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes in features matrix: 38 to 616\n",
    "# Indexes in flights matrix: 424 to 998\n",
    "\n",
    "synced_feature_matrix = features_matrix[38:616]\n",
    "synced_flights_matrix = flights_matrix[424:998]\n",
    "\n",
    "print(synced_feature_matrix.shape)\n",
    "print(synced_flights_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Day in Flight Matrix  -  Index of that day in features matrix, need to delete\n",
    "# 3/14/2021 - 378\n",
    "# 5/31/2021 - 456\n",
    "# 9/4/2021 - 552\n",
    "# 9/29/2021 - 577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synced_feature_matrix[577,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synced_feature_matrix = np.delete(synced_feature_matrix, [378, 456, 552, 577], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synced_feature_matrix.shape)\n",
    "print(synced_flights_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Node Features for nans, negatives, and prevalence of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(synced_feature_matrix == np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(synced_feature_matrix < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(synced_feature_matrix == 0)  # A few regions reported 0 overall cases in March 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Flight Matrix For Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_zeros_loc = np.where(synced_flights_matrix == 0)\n",
    "len(flight_zeros_loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_zeros_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If want to test fully connected adjacency, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synced_flights_matrix += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_zeros_loc = np.where(synced_flights_matrix == 0)\n",
    "# flight_zeros_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove self-connections in flight dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synced_flights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    synced_flights_matrix[:,idx,idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_zeros_loc = np.where(synced_flights_matrix == 0)\n",
    "print(len(flight_zeros_loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synced_flights_matrix[100,:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = synced_feature_matrix\n",
    "flights_matrix = synced_flights_matrix\n",
    "\n",
    "print(feature_matrix.shape)\n",
    "print(flights_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_split_idx = int(len(feature_matrix) * 0.8)\n",
    "train_val_split_idx = int(val_test_split_idx * 0.8)\n",
    "\n",
    "print(train_val_split_idx)\n",
    "print(val_test_split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_matrix = feature_matrix[:train_val_split_idx, :, :]\n",
    "train_flight_matrix = flights_matrix[:train_val_split_idx, :, :]\n",
    "val_feat_matrix = feature_matrix[train_val_split_idx:val_test_split_idx, :, :]\n",
    "val_flight_matrix = flights_matrix[train_val_split_idx:val_test_split_idx, :, :]\n",
    "test_feat_matrix = feature_matrix[val_test_split_idx:, :, :]\n",
    "test_flight_matrix = flights_matrix[val_test_split_idx:, :, :]\n",
    "\n",
    "print(train_feat_matrix.shape)\n",
    "print(train_flight_matrix.shape)\n",
    "print(val_feat_matrix.shape)\n",
    "print(val_flight_matrix.shape)\n",
    "print(test_feat_matrix.shape)\n",
    "print(test_flight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothen Covid Cases Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothening_window = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothen Training Dataset\n",
    "train_feature_matrix_df = pd.DataFrame(train_feat_matrix[:,:,1])\n",
    "train_rolling_win_df = train_feature_matrix_df.rolling(window=smoothening_window + 1).mean()\n",
    "train_rolling_win_df.dropna(inplace=True)\n",
    "train_rolling_win_df.plot()\n",
    "train_rolling_win_df_np = train_rolling_win_df.values\n",
    "\n",
    "# Delete first 14 days from feature and flight datasets\n",
    "train_feat_matrix = train_feat_matrix[smoothening_window:,:,:]\n",
    "train_flight_matrix = train_flight_matrix[smoothening_window:,:,:]\n",
    "\n",
    "# Overlay moving averages onto matrix that will be saved\n",
    "train_feat_matrix[:,:,1] = train_rolling_win_df_np\n",
    "print(train_feat_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothen Validation Dataset\n",
    "val_feature_matrix_df = pd.DataFrame(val_feat_matrix[:,:,1])\n",
    "val_rolling_win_df = val_feature_matrix_df.rolling(window=smoothening_window + 1).mean()\n",
    "val_rolling_win_df.dropna(inplace=True)\n",
    "val_rolling_win_df.plot()\n",
    "val_rolling_win_df_np = val_rolling_win_df.values\n",
    "\n",
    "# Delete first 14 days from feature and flight datasets\n",
    "val_feat_matrix = val_feat_matrix[smoothening_window:,:,:]\n",
    "val_flight_matrix = val_flight_matrix[smoothening_window:,:,:]\n",
    "\n",
    "# Overlay moving averages onto matrix that will be saved\n",
    "val_feat_matrix[:,:,1] = val_rolling_win_df_np\n",
    "print(val_feat_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothen Test Dataset\n",
    "test_feature_matrix_df = pd.DataFrame(test_feat_matrix[:,:,1])\n",
    "test_rolling_win_df = test_feature_matrix_df.rolling(window=smoothening_window + 1).mean()\n",
    "test_rolling_win_df.dropna(inplace=True)\n",
    "test_rolling_win_df.plot()\n",
    "test_rolling_win_df_np = test_rolling_win_df.values\n",
    "\n",
    "# Delete first 14 days from feature and flight datasets\n",
    "test_feat_matrix = test_feat_matrix[smoothening_window:,:,:]\n",
    "test_flight_matrix = test_flight_matrix[smoothening_window:,:,:]\n",
    "\n",
    "# Overlay moving averages onto matrix that will be saved\n",
    "test_feat_matrix_smooth = np.copy(test_feat_matrix)\n",
    "test_feat_matrix_smooth[:,:,1] = test_rolling_win_df_np\n",
    "print(test_feat_matrix_smooth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unscaled_flight_matrix = np.copy(train_flight_matrix)\n",
    "val_unscaled_flight_matrix = np.copy(val_flight_matrix)\n",
    "test_unscaled_flight_matrix = np.copy(test_flight_matrix)\n",
    "print(train_unscaled_flight_matrix.shape)\n",
    "print(val_unscaled_flight_matrix.shape)\n",
    "print(test_unscaled_flight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_unscaled_flight_matrix.max())\n",
    "print(train_unscaled_flight_matrix.min())\n",
    "print(val_unscaled_flight_matrix.max())\n",
    "print(val_unscaled_flight_matrix.min())\n",
    "print(test_unscaled_flight_matrix.max())\n",
    "print(test_unscaled_flight_matrix.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.where(train_flight_matrix == 0)[0]))\n",
    "print(len(np.where(val_flight_matrix == 0)[0]))\n",
    "print(len(np.where(test_flight_matrix == 0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: replaces 1s and 1.1s so that zeros are not introduced by log10 transformation of flight weights. That would affect edge creation in graph networks\n",
    "train_flight_matrix[train_flight_matrix == 1] = 1.1\n",
    "for roll_win in range(len(train_flight_matrix)):\n",
    "    for row_idx in range(len(train_flight_matrix[roll_win])):\n",
    "        for col_idx in range(len(train_flight_matrix[roll_win][row_idx])):\n",
    "            if train_flight_matrix[roll_win][row_idx][col_idx] > 0:\n",
    "                train_flight_matrix[roll_win][row_idx][col_idx] = np.log10(train_flight_matrix[roll_win][row_idx][col_idx])\n",
    "\n",
    "val_flight_matrix[val_flight_matrix == 1] = 1.1\n",
    "for roll_win in range(len(val_flight_matrix)):\n",
    "    for row_idx in range(len(val_flight_matrix[roll_win])):\n",
    "        for col_idx in range(len(val_flight_matrix[roll_win][row_idx])):\n",
    "            if val_flight_matrix[roll_win][row_idx][col_idx] > 0:\n",
    "                val_flight_matrix[roll_win][row_idx][col_idx] = np.log10(val_flight_matrix[roll_win][row_idx][col_idx])\n",
    "\n",
    "test_flight_matrix[test_flight_matrix == 1] = 1.1\n",
    "for roll_win in range(len(test_flight_matrix)):\n",
    "    for row_idx in range(len(test_flight_matrix[roll_win])):\n",
    "        for col_idx in range(len(test_flight_matrix[roll_win][row_idx])):\n",
    "            if test_flight_matrix[roll_win][row_idx][col_idx] > 0:\n",
    "                test_flight_matrix[roll_win][row_idx][col_idx] = np.log10(test_flight_matrix[roll_win][row_idx][col_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.where(train_flight_matrix == 0)[0]))\n",
    "print(len(np.where(val_flight_matrix == 0)[0]))\n",
    "print(len(np.where(test_flight_matrix == 0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_flight_matrix.max())\n",
    "print(train_flight_matrix.min())\n",
    "print(val_flight_matrix.max())\n",
    "print(val_flight_matrix.min())\n",
    "print(test_flight_matrix.max())\n",
    "print(test_flight_matrix.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that outgoing flights are log10 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "plt.figure(figsize=(30, 15))\n",
    "for j in range(10):\n",
    "    ax = plt.subplot(5,2,j+1)\n",
    "    for i in range(10):\n",
    "        if i != j:\n",
    "            # train_flight_matrix val_flight_matrix test_flight_matrix\n",
    "            # train_unscaled_flight_matrix val_unscaled_flight_matrix test_unscaled_flight_matrix\n",
    "            plt.plot(test_flight_matrix[:,j,i], label=continents[i])\n",
    "        else:\n",
    "            plt.plot(np.zeros((len(test_flight_matrix))), label=continents[i])\n",
    "    plt.title(continents[j] + \" to Other Continents\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # plt.ylim(0.0, 3.0)\n",
    "    plt.xlabel('Day Index')  \n",
    "    plt.ylabel('Number of Flights (Log10 Scale)')\n",
    "\n",
    "plt.suptitle(\"Continents Dataset v19 Test Set Flight Trends After Log10 Scaling\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"./continents_v19_test_flight_trends_log10_7day_smoothened.png\", facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Transform Covid Cases and Containment Index Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_feat_matrix[:,:,1].max())\n",
    "print(train_feat_matrix[:,:,1].min())\n",
    "print(val_feat_matrix[:,:,1].max())\n",
    "print(val_feat_matrix[:,:,1].min())\n",
    "print(train_feat_matrix[:,:,1].max())\n",
    "print(train_feat_matrix[:,:,1].min())\n",
    "print(test_feat_matrix_smooth[:,:,1].max())\n",
    "print(test_feat_matrix_smooth[:,:,1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_feat_matrix[:,:,1].shape[0]):\n",
    "    for j in range(train_feat_matrix[:,:,1].shape[1]):\n",
    "        if train_feat_matrix[i][j][1] > 0:\n",
    "            train_feat_matrix[i][j][1] = np.log10(train_feat_matrix[i][j][1])\n",
    "        train_feat_matrix[i][j][0] = np.log10(train_feat_matrix[i][j][0])\n",
    "\n",
    "for i in range(val_feat_matrix[:,:,1].shape[0]):\n",
    "    for j in range(val_feat_matrix[:,:,1].shape[1]):\n",
    "        if val_feat_matrix[i][j][1] > 0:\n",
    "            val_feat_matrix[i][j][1] = np.log10(val_feat_matrix[i][j][1])\n",
    "        val_feat_matrix[i][j][0] = np.log10(val_feat_matrix[i][j][0])\n",
    "\n",
    "for i in range(test_feat_matrix[:,:,1].shape[0]):\n",
    "    for j in range(test_feat_matrix[:,:,1].shape[1]):\n",
    "        if test_feat_matrix[i][j][1] > 0:\n",
    "            test_feat_matrix[i][j][1] = np.log10(test_feat_matrix[i][j][1])\n",
    "        test_feat_matrix[i][j][0] = np.log10(test_feat_matrix[i][j][0])\n",
    "\n",
    "for i in range(test_feat_matrix_smooth[:,:,1].shape[0]):\n",
    "    for j in range(test_feat_matrix_smooth[:,:,1].shape[1]):\n",
    "        if test_feat_matrix_smooth[i][j][1] > 0:\n",
    "            test_feat_matrix_smooth[i][j][1] = np.log10(test_feat_matrix_smooth[i][j][1])\n",
    "        test_feat_matrix_smooth[i][j][0] = np.log10(test_feat_matrix_smooth[i][j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_feat_matrix[:,:,1].max())\n",
    "print(train_feat_matrix[:,:,1].min())\n",
    "print(val_feat_matrix[:,:,1].max())\n",
    "print(val_feat_matrix[:,:,1].min())\n",
    "print(test_feat_matrix[:,:,1].max())\n",
    "print(test_feat_matrix[:,:,1].min())\n",
    "print(test_feat_matrix_smooth[:,:,1].max())\n",
    "print(test_feat_matrix_smooth[:,:,1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_flight_matrix.max())\n",
    "print(train_unscaled_flight_matrix.max())\n",
    "print(val_flight_matrix.max())\n",
    "print(val_unscaled_flight_matrix.max())\n",
    "print(test_flight_matrix.max())\n",
    "print(test_unscaled_flight_matrix.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flight_matrix[72,:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./10_continents_dataset_v19_training',\n",
    "    train_features_log10=train_feat_matrix,\n",
    "    train_log10_scaled_flight_matrix=train_flight_matrix,\n",
    "    train_unscaled_flight_matrix=train_unscaled_flight_matrix,\n",
    "    val_features_log10=val_feat_matrix,\n",
    "    val_log10_scaled_flight_matrix=val_flight_matrix,\n",
    "    val_unscaled_flight_matrix=val_unscaled_flight_matrix,\n",
    "    test_features_log10_unsmooth=test_feat_matrix,\n",
    "    test_features_log10_smooth=test_feat_matrix_smooth,\n",
    "    test_log10_scaled_flight_matrix=test_flight_matrix,\n",
    "    test_unscaled_flight_matrix=test_unscaled_flight_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c3ec5cb0d81e7b9f9908a53ca28aa4318265e5d52f388cac911a9765dd2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
